<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>MML | GWXX</title><meta name="author" content="GWXX"><meta name="copyright" content="GWXX"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="# 多模态学习 (MultiModal Learning) # 定义 多模态机器学习，英文全称 MultiModal Machine Learning (MMML) # 模态 ​		模态，是指一些表达或感知事物的方式，每一种信息的来源或者形式，都可以称为一种模态。例如，人有触觉，听觉，视觉，嗅觉；信息的媒介，有语音、视频、文字等；多种多样的传感器，如雷达、红外、加速度计等，以上的每一种都可以称为一">
<meta property="og:type" content="article">
<meta property="og:title" content="MML">
<meta property="og:url" content="http://aer0liteee.github.io/post/bdbefb72.html">
<meta property="og:site_name" content="GWXX">
<meta property="og:description" content="# 多模态学习 (MultiModal Learning) # 定义 多模态机器学习，英文全称 MultiModal Machine Learning (MMML) # 模态 ​		模态，是指一些表达或感知事物的方式，每一种信息的来源或者形式，都可以称为一种模态。例如，人有触觉，听觉，视觉，嗅觉；信息的媒介，有语音、视频、文字等；多种多样的传感器，如雷达、红外、加速度计等，以上的每一种都可以称为一">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://aer0liteee.github.io/img/avatar.jpg">
<meta property="article:published_time" content="2023-07-16T14:44:07.000Z">
<meta property="article:modified_time" content="2023-07-16T14:45:42.781Z">
<meta property="article:author" content="GWXX">
<meta property="article:tag" content="MultiModal Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://aer0liteee.github.io/img/avatar.jpg"><link rel="shortcut icon" href="https://pic.imgdb.cn/item/64a6dfb61ddac507cce683c1.png"><link rel="canonical" href="http://aer0liteee.github.io/post/bdbefb72.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'MML',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-07-16 22:45:42'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><script src="https://cdn.bootcdn.net/ajax/libs/clipboard.js/2.0.11/clipboard.min.js"></script> <script src="/js/ClipboardJS.js"></script> <link rel="stylesheet" href="/css/modify.css"> <link rel="stylesheet" href="/css/universe.css"> <link rel="stylesheet" href="/css/custom.css"  media="defer" onload="this.media='all'"> <script src="/js/sun_moon.js" async></script> <script src="/js/inform.js" async></script> <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/mainColor/heoMainColor.css"> <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/poem/poem.css"> <script src="https://ali-oss.xmwpro.com/cdn/js/three.min.js"></script><svg aria-hidden="true" style="position:absolute; overflow:hidden; width:0; height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div class="float-box left top"></div><div class="float-box left bottom"></div><div class="float-box right top"></div><div class="float-box right bottom"></div><script>window.paceOptions = {
  restartOnPushState: false
}

document.addEventListener('pjax:send', () => {
  Pace.restart()
})
</script><link rel="stylesheet" href="https://fastly.jsdelivr.net/gh/xlenco/JS-X@main/pace.js/pace.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="canvas-container" id="canvas"></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="GWXX"><span class="site-name">GWXX</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">MML</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-07-16T14:44:07.000Z" title="发表于 2023-07-16 22:44:07">2023-07-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-16T14:45:42.781Z" title="更新于 2023-07-16 22:45:42">2023-07-16</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Deep-learning/">Deep-learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>11分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="MML"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="多模态学习multimodal-learning"><a class="markdownIt-Anchor" href="#多模态学习multimodal-learning">#</a> 多模态学习 (MultiModal Learning)</h1>
<h2 id="定义"><a class="markdownIt-Anchor" href="#定义">#</a> 定义</h2>
<p><strong><u>多模态机器学习</u></strong>，英文全称 MultiModal Machine Learning (MMML)</p>
<h3 id="模态"><a class="markdownIt-Anchor" href="#模态">#</a> 模态</h3>
<p>​		<strong>模态</strong>，是指一些表达或感知事物的方式，每一种<u>信息的来源或者形式</u>，都可以称为一种模态。例如，人有触觉，听觉，视觉，嗅觉；信息的媒介，有语音、视频、文字等；多种多样的传感器，如雷达、红外、加速度计等，以上的每一种都可以称为一种模态。</p>
<p><img src="https://oss.imzhanghao.com/img/202211051318189.png" alt="What is Mulimodel"></p>
<p>​															  	<strong><u>感知模态</u></strong></p>
<ul>
<li>​		我们生活在一个由多种模态（Multimodal）信息构成的世界，包括<strong>视觉信息、听觉信息、文本信息、嗅觉信息</strong>等等，当研究的问题或者数据集包含多种这样的模态信息时我们称之为多模态问题，研究多模态问题是推动人工智能更好的了解和认知我们周围世界的关键。</li>
</ul>
<blockquote>
<p>相较于图像、语音、文本等多媒体 (Multi-media) 数据划分形式，“模态” 是一个更为细粒度的概念，<strong>同一媒介下可存在不同的模态</strong>。</p>
<p>比如我们可以把<u>两种不同的语言当做是两种模态</u>，甚至在<u>两种不同情况下采集到的数据集</u>，亦可认为是两种模态。</p>
</blockquote>
<h3 id="多模态"><a class="markdownIt-Anchor" href="#多模态">#</a> 多模态</h3>
<p>​		<strong>多模态</strong>，即是从多个模态表达或感知事物。 多模态可归类为<u>同质性的模态</u>，例如从两台相机中分别拍摄的图片；<u>异质性的模态</u>，例如图片与文本语言的关系。</p>
<p>​	<strong>多模态可能有以下三种形式：</strong></p>
<ul>
<li>
<p><strong>来自不同传感器的同一类媒体数据</strong>。如物联网背景下<u>不同传感器所检测到的同一对象数据</u>等。</p>
</li>
<li>
<p><strong>具有不同的数据结构特点、表示形式的表意符号与信息</strong>。如描述同一对象的结构化、非结构化的数据单元；描述<u>同一数学概念的公式、逻辑符号、函数图及解释性文本</u>等。</p>
</li>
<li>
<p><strong>描述同一对象的多媒体数据</strong>。如互联网环境下描述某一特定对象的<u>视频、图片、语音、文本</u>等信息。</p>
<p>​											下图即为典型的多模态信息形式</p>
<p><img src="https://oss.imzhanghao.com/img/202211050816652.png" alt="“下雪”场景的多模态数据(图像、音频与文本)"></p>
<p>通常主要研究模态包括 &quot;<strong>3V</strong>&quot;：即<strong> Verbal (文本)、Vocal (语音)、Visual (视觉)</strong>。</p>
<p>​	人跟人交流时的多模态：</p>
<ul>
<li>视觉
<ul>
<li>手势：头、眼、手</li>
<li>肢体语言：体态、空间距离关系</li>
<li>眼神交流：头、眼</li>
<li>面部表情：笑容、皱眉……</li>
</ul>
</li>
<li>语言
<ul>
<li>韵律：语调、语音质量</li>
<li>声音：哭、笑……</li>
</ul>
</li>
</ul>
<p><img src="https://oss.imzhanghao.com/img/202211051318784.png" alt="multimodal communicative behaviors"></p>
<h3 id="多模态机器学习"><a class="markdownIt-Anchor" href="#多模态机器学习">#</a> 多模态机器学习</h3>
<p>​	<strong>多模态机器学习</strong>是从多种模态的数据中学习并且提升自身的算法，它不是某一个具体的算法，它是一类算法的总称。</p>
<p>从<strong>语义感知</strong>的角度切入，多模态数据涉及<strong>不同的感知通道</strong>如视觉、听觉、触觉、嗅觉所接收到的信息；在<strong>数据层面</strong>理解，多模态数据则可被看作<strong>多种数据类型</strong>的组合，如图片、数值、文本、符号、音频、时间序列，或者集合、树、图等不同数据结构所组成的复合数据形式，乃至来自不同数据库、不同知识库的各种信息资源的组合。<strong>对多源异构数据的挖掘分析可被理解为多模态学习</strong>。</p>
<p><img src="https://oss.imzhanghao.com/img/202211051125254.png" alt="多模态学习举例"></p>
<p>​	   将同个对象（同一种数据）的不同输出形式进行多模态学习融合后进行预测</p>
</li>
</ul>
<h2 id="发展历史"><a class="markdownIt-Anchor" href="#发展历史">#</a> 发展历史</h2>
<p><img src="https://oss.imzhanghao.com/img/202211051008371.png" alt="多模态发展的四个时期"></p>
<h3 id="行为时代"><a class="markdownIt-Anchor" href="#行为时代">#</a> 行为时代</h3>
<p>从心理学的角度对多模态这一现象进行剖析。</p>
<h3 id="计算时代"><a class="markdownIt-Anchor" href="#计算时代">#</a> 计算时代</h3>
<p>利用一些浅层的模型对多模态问题进行研究，其中代表性的应用包括视觉语音联合识别，多模态情感计算等等。</p>
<h3 id="交互时代"><a class="markdownIt-Anchor" href="#交互时代">#</a> 交互时代</h3>
<p>从交互的角度入手，研究多模态识别问题，拟人类多模态交互过程，其中主要的代表作品包括苹果的语音助手 Siri、IDIAP 实验室（瑞士人工智能研究机构）的 AMI 项目（记录会议录音、同步音频视频、转录与注释）等。</p>
<h3 id="深度学习时代"><a class="markdownIt-Anchor" href="#深度学习时代">#</a> 深度学习时代</h3>
<p>多模态研究发展迅猛，得益于新的大规模多模态数据集、GPU 快速计算、强大的视觉特征抽取能力、强大的语言特征抽取能力。</p>
<p><img src="https://oss.imzhanghao.com/img/202211050837453.png" alt="多模态机器学习在Google Trends上的表现"></p>
<h2 id="典型任务"><a class="markdownIt-Anchor" href="#典型任务">#</a> 典型任务</h2>
<h3 id="language-audio"><a class="markdownIt-Anchor" href="#language-audio">#</a> Language-Audio</h3>
<ul>
<li>Text-to-Speech Synthesis: 给定文本，生成一段对应的声音。</li>
<li>Audio Captioning：给定一段语音，生成一句话总结并描述主要内容。(不是语音识别)</li>
</ul>
<h3 id="vision-audio"><a class="markdownIt-Anchor" href="#vision-audio">#</a> Vision-Audio</h3>
<ul>
<li>
<p>Speech-conditioned Face generation：给定一段话，生成说话人的视频。</p>
</li>
<li>
<p>Audio-Driven 3D Facial Animation：<u>给定一段话与 3D 人脸模版，生成说话的人脸 3D 动画。</u></p>
<ul>
<li>
<p>​				Apple Vision Pro 头显 + Otter AI 助手：打造全新空间计算体验</p>
<p><img src="https://www.apple.com/v/apple-vision-pro/a/images/overview/hero/portrait_base__bwsgtdddcl7m_large.jpg" alt="Person wearing Vision Pro, with eyes visible through front glass"></p>
<p>​	苹果在 2023 年的全球开发者大会上发布了一款令人惊艳的产品：Vision Pro。</p>
<p>​			超高清的显示屏、先进的空间音频系统、无需手柄的手眼语音交互。</p>
<p>Otter 是一个基于深度学习的多模态 AI 助手，它可以通过 Vision Pro 头显的摄像头捕捉用户的视觉输入，分析用户的环境、情境和意图，生成相应的反馈和指导。Otter 可以理解用户的语言、手势和眼神，与用户进行自然和流畅的对话，帮助用户完成各种任务和活动。</p>
<p><img src="E:%5C%E6%A1%8C%E9%9D%A2%5CGZ%5C%E5%A4%A7%E4%BA%8C%E4%B8%8B%5C8e6b2a5ce8574900a91d6693d9e5ccc5.gif" alt="img"></p>
<p>捕获用户视觉、语音输入特征，根据已采集的人脸面部信息生成说话的人脸 3D 动画</p>
</li>
</ul>
</li>
</ul>
<h3 id="vision-language"><a class="markdownIt-Anchor" href="#vision-language">#</a> Vision-Language</h3>
<ul>
<li>Image/Video Captioning (图像 / 视频描述)：给定一个图像 / 视频，生成文本描述其主要内容。</li>
<li>Vision-and-Language Navigation (视觉 - 语言导航)： 给定自然语言进行指导，使得智能体根据视觉传感器导航到特定的目标。</li>
</ul>
<h3 id="定位相关任务"><a class="markdownIt-Anchor" href="#定位相关任务">#</a> 定位相关任务</h3>
<ul>
<li>Object Tracking from Natural Language Query: 给定一段视频和一些文本，追踪视频中文本所描述的对象。</li>
</ul>
<h3 id="更多模态"><a class="markdownIt-Anchor" href="#更多模态">#</a> 更多模态</h3>
<ul>
<li>Affect Computing (情感计算)：使用语音、视觉 (人脸表情)、文本信息、心电、脑电等模态进行情感识别。</li>
</ul>
<h2 id="核心技术挑战"><a class="markdownIt-Anchor" href="#核心技术挑战">#</a> 核心技术挑战</h2>
<p>​                                                 <u>表征</u> <u>翻译</u> <u>对齐</u> <u>融合</u> <u>协同学习</u></p>
<p><img src="https://oss.imzhanghao.com/img/202211051339734.png" alt="多模态学习的技术挑战"></p>
<h3 id="表征representation"><a class="markdownIt-Anchor" href="#表征representation">#</a> 表征 Representation</h3>
<p>​	第一个基本挑战是学习如何<strong>利用多种模态的互补性和冗余性的方式表示和总结多模态数据</strong>（<u>个人理解，即如何表示数据让计算机看得懂、能处理</u>）。多模态数据的异质性使得构建这样的表示具有挑战性，例如，语言通常是象征性的，而音频和视觉形式将被表示为信号。</p>
<blockquote>
<p>​	<strong>单模态的表征负责将信息表示为计算机可以处理的数值向量或者进一步抽象为更高层的特征向量。</strong></p>
<p>​	<strong>多模态表征是指通过利用多模态之间的互补性，剔除模态间的冗余性，从而学习到更好的特征表示。</strong></p>
</blockquote>
<p><img src="https://oss.imzhanghao.com/img/202211051431550.png" alt="Representation"></p>
<h4 id="联合表征"><a class="markdownIt-Anchor" href="#联合表征">#</a> 联合表征</h4>
<p>​	<strong>联合表征</strong>（Joint Representation）<u>将多个模态的信息一起映射到一个统一的多模态向量空间</u>，Joint 结构注重捕捉多模态的<strong>互补性</strong>，融合多个输入模态 x1 , x2 获得多模态表征 Xm = f (x1 ,…,xn)，进而利用 Xm 完成某种预测任务。</p>
<p><img src="https://oss.imzhanghao.com/img/202211052136742.png" alt="Joint Representation"></p>
<p>​	Multimodal learning with deep boltzmann machines (NIPS 2012) 提出将 deep boltzmann machines（DBM） 结构扩充到多模态领域，通过 Multimodal DBM，可以学习到多模态的<strong>联合概率分布</strong>。</p>
<p><img src="https://oss.imzhanghao.com/img/202211051458819.png" alt="Multimodal DBM 模型"></p>
<p>​	在获得图像与文本间的<strong>联合概率分布</strong>后，在应用阶段：</p>
<ul>
<li>输入图片，<u>利用条件概率 P (文本 | 图片)，生成文本特征</u>，可以得到图片相应的文本描述；</li>
<li>输入文本，<u>利用条件概率 P (图片 | 文本)，可以生成图片特征</u>，通过检索出最靠近该特征向量的两个图片实例，可以得到符合文本描述的图片。</li>
</ul>
<p><img src="https://oss.imzhanghao.com/img/202211051506598.png" alt="Multimodal DBM 应用"></p>
<h4 id="协同表征"><a class="markdownIt-Anchor" href="#协同表征">#</a> 协同表征</h4>
<p>​	协同表征（Coordinated Representation）<u>将多模态中的每个模态分别映射到各自的表示空间，但映射后的向量之间满足一定的相关性约束（例如线性相关）</u>。Coordinated 结构并不寻求融合而是建模多种模态数据间的<strong>相关性</strong>，它将多个 (通常是两个) 模态映射到协作空间，表示为：f (x1)～g (x2)，其中 **<u>～</u>** 表示一种协作关系。网络的优化目标是这种协作关系 (通常是相似性，即最小化 cosine 距离等度量)。</p>
<p><img src="https://oss.imzhanghao.com/img/202211052203950.png" alt="Coordinated Representation"></p>
<p>​	<u>NIPS 2014</u>（一个关于机器学习和计算神经科学领域的人工智能国际会议) ，利用<strong>协同学习到的特征向量之间满足加减算数运算</strong>这一特性，可以搜索出与给定图片满足 “<strong>指定的转换语义</strong>” 的图片。例如：狗的图片特征向量 - 狗的文本特征向量 + 猫的文本特征向量 = 猫的图片特征向量 -&gt; 在特征向量空间，根据最近邻距离，检索得到猫的图片。</p>
<p><img src="https://oss.imzhanghao.com/img/202211090619157.png" alt="多模态向量空间运算"></p>
<h3 id="翻译translation"><a class="markdownIt-Anchor" href="#翻译translation">#</a> 翻译 Translation</h3>
<p>​	第二个挑战涉及<strong>如何将数据从一种模式转化（映射）到另一种模式</strong>。不仅数据是异构的，而且模态之间的关系通常是开放式的或主观的。例如，存在多种描述图像的正确方法，并且可能不存在一种完美的翻译。</p>
<p>​												<u>基于实例的方法</u> <u>模型驱动的方法</u></p>
<p><img src="https://oss.imzhanghao.com/img/202211051434189.png" alt="Translation"></p>
<h4 id="常见应用"><a class="markdownIt-Anchor" href="#常见应用">#</a> 常见应用</h4>
<ul>
<li><strong>机器翻译（Machine Translation）</strong>：将输入的语言 A（即时）翻译为另一种语言 B。类似的还有唇读（Lip Reading）和语音翻译 （Speech Translation），分别将唇部视觉和语音信息转换为文本信息。</li>
<li><strong>图片描述（Image captioning) 或者视频描述（Video captioning)</strong>： 对给定的图片 / 视频形成一段文字描述，以表达图片 / 视频的内容。</li>
<li><strong>语音合成（Speech Synthesis）</strong>：根据输入的文本信息，自动合成一段语音信号。</li>
</ul>
<h4 id="翻译的评估困境"><a class="markdownIt-Anchor" href="#翻译的评估困境">#</a> 翻译的评估困境</h4>
<p>​	多模态翻译方法面临的一个主要挑战是它们很难评估（<u>即在无对错之分的情况下判断哪个是更好的</u>）。语音识别等任务只有一个正确的翻译，而语音合成和媒体描述等任务则没有。有时，就像在语言翻译中，多重答案是正确的，决定哪个翻译更好往往是主观的。</p>
<ul>
<li><strong>人工评价</strong>是最理想的评估，但是<u>耗时耗钱</u>，且需要多样化打分人群的背景以避免偏见。</li>
<li><strong>自动化指标</strong>是视觉描述领域常用的替代方法，包括 BLEU，Meteor，CIDEr，ROUGE 等，但它们被证实与人的评价相关性较弱。</li>
<li><strong>基于检索的评估</strong>和<strong>弱化任务</strong>，例如：将图像描述中一对多映射简化为 VQA（<u>给机器一张图片和一个开放式的的自然语言问题，要求机器输出自然语言答案，答案可以是以下任何形式：短语、单词、 (yes/no)、从几个可能的答案中选择正确答案。 VQA 是一个典型的多模态问题，计算机需要同时学会理解图像和文字。</u>）中一对一的映射，也是解决评估困境的手段。</li>
</ul>
<h3 id="对齐alignment"><a class="markdownIt-Anchor" href="#对齐alignment">#</a> 对齐 Alignment</h3>
<p>​	第三个挑战是从<strong>两种或多种不同的模态中识别（子）元素之间的直接关系</strong>。例如，我们可能希望<u>将食谱中的步骤与显示正在制作的菜肴的视频对齐</u>。为了应对这一挑战，我们需要测量不同模式之间的相似性并处理可能的长期依赖和歧义。</p>
<p>​														显式对齐 隐式对齐</p>
<p><img src="https://oss.imzhanghao.com/img/202211051433591.png" alt="Alignment"></p>
<h4 id="显式对齐"><a class="markdownIt-Anchor" href="#显式对齐">#</a> 显式对齐</h4>
<p>​	如果模型的<strong>主要目标是对齐来自两个或多个模态的子元素</strong>，那么我们将其分类为执行显式对齐。显式对齐的一个重要工作是<strong>相似性度量</strong>。大多数方法都依赖于度量不同模态的子组件之间的相似性作为基本构建块。</p>
<p><img src="https://oss.imzhanghao.com/img/202211071349090.png" alt="显式对齐"></p>
<p>包括无监督和弱监督的方法：</p>
<ul>
<li><strong>无监督对齐</strong>：给定两个模态的数据作为输入，希望模型实现子元素的对齐，但是训练数据没有 “对齐结果” 的标注，模型需要同时学习相似度度量和对齐方式。</li>
<li><strong>有监督对齐</strong>：有监督方法存在标注，可训练模型学习相似度度量。</li>
</ul>
<h4 id="隐式对齐"><a class="markdownIt-Anchor" href="#隐式对齐">#</a> 隐式对齐</h4>
<p>​	隐式对齐<strong>用作另一个任务的中间 (通常是潜在的) 步骤。</strong> 这允许在许多任务中有更好的表现，包括语音识别、机器翻译、媒体描述和视觉问题回答。这些模型不显式地对齐数据，也不依赖于监督对齐示例，而是学习如何在模型训练期间潜在地对齐数据。</p>
<p><img src="https://oss.imzhanghao.com/img/202211071428784.png" alt="隐式对齐"></p>
<h3 id="融合fusion"><a class="markdownIt-Anchor" href="#融合fusion">#</a> 融合 Fusion</h3>
<p>​	第四个挑战是<strong>结合来自两个或多个模态的信息</strong>来执行<u>预测</u>。例如，对于视听语音识别，将嘴唇运动的视觉描述与语音信号融合以预测口语。来自不同模态的信息可能具有不同的预测能力和噪声拓扑，并且可能在至少一种模态中丢失数据。</p>
<p>​															模型无关的方法</p>
<p><img src="https://oss.imzhanghao.com/img/202211051435164.png" alt="Fusion"></p>
<h4 id="模型无关的方法"><a class="markdownIt-Anchor" href="#模型无关的方法">#</a> 模型无关的方法</h4>
<p>​															基于模型的方法</p>
<p><img src="https://oss.imzhanghao.com/img/202211051436546.png" alt="Fusion"></p>
<h4 id="基于模型的方法"><a class="markdownIt-Anchor" href="#基于模型的方法">#</a> 基于模型的方法</h4>
<h3 id="协同学习co-learning"><a class="markdownIt-Anchor" href="#协同学习co-learning">#</a> 协同学习 Co-learning</h3>
<p>​	第五个挑战是在模态的表示和它们的预测模型之间转移知识。协同学习探索了<strong>如何从一种模态中学习的知识帮助在不同模态上训练的计算模型</strong>（<u>使用一个资源丰富的模态信息来辅助另一个资源相对贫瘠的模态进行学习</u>）。当其中一种模式的资源有限（例如，带注释的数据）时，这一挑战尤其重要。辅助模态（helper modality）通常只参与模型的训练过程，并不参与模型	的测试使用过程</p>
<p><img src="https://oss.imzhanghao.com/img/202211051437074.png" alt="Co-learning"></p>
<h4 id="并行"><a class="markdownIt-Anchor" href="#并行">#</a> 并行</h4>
<p>​	需要训练数据集，其中来自一种模态的观察结果与来自其他模态的观察结果直接相关，例如在一个视听语音数据集中，视频和语音样本来自同一个说话者。</p>
<h4 id="非并行"><a class="markdownIt-Anchor" href="#非并行">#</a> 非并行</h4>
<p>​	不需要来自不同模式的观察结果之间的直接联系，通常通过使用类别重叠来实现共同学习，例如，在零样本学习中，使用来自 Wikipedia 的纯文本数据集扩展传统的视觉对象识别数据集以改进视觉对象识别的泛化能力。</p>
<h4 id="混合"><a class="markdownIt-Anchor" href="#混合">#</a> 混合</h4>
<p>​	通过共享模式或数据集桥接</p>
<h2 id="sota模型-clip"><a class="markdownIt-Anchor" href="#sota模型-clip">#</a> SOTA 模型 - CLIP</h2>
<p>​	<strong>CLIP</strong>，全称 Contrastive Language-Image Pre-training，是 OpenAI 最新的一篇 NLP 和 CV 结合的<u>多模态</u>的工作，在多模态领域迈出了重要的一步。</p>
<p><img src="https://oss.imzhanghao.com/img/202211081504107.png" alt="CLIP Zero shot"></p>
<p>​			CLIP 主要的贡献就是<u>利用无监督的文本信息，作为监督信号来学习视觉特征</u>。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://Aer0Liteee.github.io">GWXX</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://aer0liteee.github.io/post/bdbefb72.html">http://aer0liteee.github.io/post/bdbefb72.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://Aer0Liteee.github.io" target="_blank">GWXX</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/MultiModal-Learning/">MultiModal Learning</a></div><div class="post_share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/post/44ee844e.html" title="DASCTF-2023-0X401--WP"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">DASCTF-2023-0X401--WP</div></div></a></div><div class="next-post pull-right"><a href="/post/f862a75e.html" title="Cyber-Code-Intelligence-for-malware-detection"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Cyber-Code-Intelligence-for-malware-detection</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">GWXX</div><div class="author-info__description">多少繁华如梦 曾经万紫千红</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Aer0Liteee"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Aer0Liteee" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:Aer0Liteeee@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><b><font color="#e66b6d">足</font> <font color="#e66d98">履</font> <font color="#e66cc6">实</font> <font color="#cc6de6">地</font> , <font color="#cde670">能</font> <font color="#e6df72">见</font> <font color="#e6c073">星</font> <font color="#e6a271">河</font> <p align="center"><img src="https://haiyong.site/img/img-blog.csdnimg.cn/f7384c88956d4378b72e47548e19c9f8.gif" width="50" alt="mao"></p> <p align="center">微信号：NULL</p> <p align="center">QQ号：NULL</p></div></div><div class="card-widget" id="card-poem"><div id="poem_sentence"></div><div id="poem_info"><div id="poem_dynasty"></div><div id="poem_author"></div></div></div><script src="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/poem/jinrishici.js" charset="utf-8"></script><script type="text/javascript">jinrishici.load(function(result) {
var sentence = document.querySelector("#poem_sentence")
var author = document.querySelector("#poem_author")
var dynasty = document.querySelector("#poem_dynasty")

var sentenceText = result.data.content
sentenceText = sentenceText.substr(0, sentenceText.length - 1);
sentence.innerHTML = sentenceText
dynasty.innerHTML = result.data.origin.dynasty
author.innerHTML = result.data.origin.author + '《' + result.data.origin.title + '》'
});</script><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AD%A6%E4%B9%A0multimodal-learning"><span class="toc-number">1.</span> <span class="toc-text"> 多模态学习 (MultiModal Learning)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-number">1.1.</span> <span class="toc-text"> 定义</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E6%80%81"><span class="toc-number">1.1.1.</span> <span class="toc-text"> 模态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81"><span class="toc-number">1.1.2.</span> <span class="toc-text"> 多模态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.1.3.</span> <span class="toc-text"> 多模态机器学习</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2"><span class="toc-number">1.2.</span> <span class="toc-text"> 发展历史</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%8C%E4%B8%BA%E6%97%B6%E4%BB%A3"><span class="toc-number">1.2.1.</span> <span class="toc-text"> 行为时代</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%97%B6%E4%BB%A3"><span class="toc-number">1.2.2.</span> <span class="toc-text"> 计算时代</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%A4%E4%BA%92%E6%97%B6%E4%BB%A3"><span class="toc-number">1.2.3.</span> <span class="toc-text"> 交互时代</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%97%B6%E4%BB%A3"><span class="toc-number">1.2.4.</span> <span class="toc-text"> 深度学习时代</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B8%E5%9E%8B%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.3.</span> <span class="toc-text"> 典型任务</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#language-audio"><span class="toc-number">1.3.1.</span> <span class="toc-text"> Language-Audio</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#vision-audio"><span class="toc-number">1.3.2.</span> <span class="toc-text"> Vision-Audio</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#vision-language"><span class="toc-number">1.3.3.</span> <span class="toc-text"> Vision-Language</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%BD%8D%E7%9B%B8%E5%85%B3%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.3.4.</span> <span class="toc-text"> 定位相关任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9B%B4%E5%A4%9A%E6%A8%A1%E6%80%81"><span class="toc-number">1.3.5.</span> <span class="toc-text"> 更多模态</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E6%8C%91%E6%88%98"><span class="toc-number">1.4.</span> <span class="toc-text"> 核心技术挑战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%A8%E5%BE%81representation"><span class="toc-number">1.4.1.</span> <span class="toc-text"> 表征 Representation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%81%94%E5%90%88%E8%A1%A8%E5%BE%81"><span class="toc-number">1.4.1.1.</span> <span class="toc-text"> 联合表征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%8F%E5%90%8C%E8%A1%A8%E5%BE%81"><span class="toc-number">1.4.1.2.</span> <span class="toc-text"> 协同表征</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BF%BB%E8%AF%91translation"><span class="toc-number">1.4.2.</span> <span class="toc-text"> 翻译 Translation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E5%BA%94%E7%94%A8"><span class="toc-number">1.4.2.1.</span> <span class="toc-text"> 常见应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BF%BB%E8%AF%91%E7%9A%84%E8%AF%84%E4%BC%B0%E5%9B%B0%E5%A2%83"><span class="toc-number">1.4.2.2.</span> <span class="toc-text"> 翻译的评估困境</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E9%BD%90alignment"><span class="toc-number">1.4.3.</span> <span class="toc-text"> 对齐 Alignment</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%98%BE%E5%BC%8F%E5%AF%B9%E9%BD%90"><span class="toc-number">1.4.3.1.</span> <span class="toc-text"> 显式对齐</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%90%E5%BC%8F%E5%AF%B9%E9%BD%90"><span class="toc-number">1.4.3.2.</span> <span class="toc-text"> 隐式对齐</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%9E%8D%E5%90%88fusion"><span class="toc-number">1.4.4.</span> <span class="toc-text"> 融合 Fusion</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%97%A0%E5%85%B3%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">1.4.4.1.</span> <span class="toc-text"> 模型无关的方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">1.4.4.2.</span> <span class="toc-text"> 基于模型的方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%8F%E5%90%8C%E5%AD%A6%E4%B9%A0co-learning"><span class="toc-number">1.4.5.</span> <span class="toc-text"> 协同学习 Co-learning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C"><span class="toc-number">1.4.5.1.</span> <span class="toc-text"> 并行</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%9E%E5%B9%B6%E8%A1%8C"><span class="toc-number">1.4.5.2.</span> <span class="toc-text"> 非并行</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%B7%E5%90%88"><span class="toc-number">1.4.5.3.</span> <span class="toc-text"> 混合</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sota%E6%A8%A1%E5%9E%8B-clip"><span class="toc-number">1.5.</span> <span class="toc-text"> SOTA 模型 - CLIP</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/25fed40f.html" title="无线网络威胁基于ARP欺骗的中间人攻击技术与防御">无线网络威胁基于ARP欺骗的中间人攻击技术与防御</a><time datetime="2024-05-29T14:49:47.000Z" title="发表于 2024-05-29 22:49:47">2024-05-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/d1c69b0f.html" title="记两道CTF题">记两道CTF题</a><time datetime="2023-08-06T08:40:39.000Z" title="发表于 2023-08-06 16:40:39">2023-08-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/44ee844e.html" title="DASCTF-2023-0X401--WP">DASCTF-2023-0X401--WP</a><time datetime="2023-08-06T08:39:08.000Z" title="发表于 2023-08-06 16:39:08">2023-08-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/bdbefb72.html" title="MML">MML</a><time datetime="2023-07-16T14:44:07.000Z" title="发表于 2023-07-16 22:44:07">2023-07-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/f862a75e.html" title="Cyber-Code-Intelligence-for-malware-detection">Cyber-Code-Intelligence-for-malware-detection</a><time datetime="2023-07-09T10:15:13.000Z" title="发表于 2023-07-09 18:15:13">2023-07-09</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By GWXX</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div><div class="container" id="jsi-flying-fish-container"></div><style>@media only screen and (max-width: 767px){
  #sidebar_search_box input[type=text]{width:calc(100% - 24px)}
}</style></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><a class="icon-V hidden" onclick="switchNightMode()" title="浅色和深色模式转换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button class="share" type="button" title="分享链接" onclick="share()"><i class="fas fa-share-nodes"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><canvas id="universe"></canvas> <script defer src="/js/jquery.js"></script> <script defer src="/js/universe.js"></script> <script defer src="/js/foot.js"></script> <div class="aplayer no-destroy" data-id="8531760283" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="random" data-preload="none" data-autoplay="false" muted></div> <script async src="/js/grayscale.js"></script> <script async data-pjax src="/js/sky.js"></script> <script data-pjax src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN@latest/js/fish.js"></script> <script async src="//at.alicdn.com/t/font_2264842_3izu8i5eoc2.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var qweather_key = '25e71c4c6c5446169ecbd2211fa940f1';
  var gaud_map_key = 'de0f097fe7882b17b80f7ae780f26f55';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '113.23,23.16';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><!-- hexo injector body_end end --></body></html>